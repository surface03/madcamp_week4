{
  "uid": "naver_385",
  "article_url": "https://n.news.naver.com/mnews/article/421/0007302866?sid=104",
  "title_text": "50피트 인공지능(AI)의 습격",
  "body_text": "\n\n[NYT 터닝 포인트 2024][편집자주] '사실 앞에 겸손한 정통 민영 뉴스통신' 뉴스1이 뉴욕타임스(NYT)와 함께 펴내는 '뉴욕타임스 터닝 포인트 2024'가 발간됐다. '터닝 포인트'는 전 세계 정치 경제 사회 문화 각 분야별 '전환점'을 짚어 독자 스스로 미래를 판단하고 대비할 수 있도록 가이드라인을 제시하는 지침서다.\n\n\n\nⓒ 뉴스1 (출처 = NYT 터닝 포인트 2024)(서울=뉴스1) 김예슬 기자 = 터닝 포인트: 세계 최고의 인공지능(AI) 기업 경영진이 공개서한을 통해 AI 기술이 인류에게 ‘멸종의 위험’을 초래한다고 경고한다.AI가 정말로 우리 호모 사피엔스를 멸종시키기 직전인가? 우리 인류는 AI를 두려워해야 하나?  AI는 SF에서 흔히 볼 수 있는 골칫거리인 소재다. 예를 들어, 영화 ‘2001 스페이스 오디세이’의 AI 컴퓨터 ‘HAL 9000’이나 ‘터미네이터’의 ‘스카이 넷’이 그렇다.우리가 창조해낸 영혼 없는 악의적인 컴퓨터가 거꾸로 우리를 파괴한다. 그리고 지금 당장 우리는 인터넷에서 AI가 실현한 최신 기술에 관한 관련 기사를 거의 하루도 빠짐없이 매일 접한다. 우리는 우리 자신의 퇴화를 묵인하고 있는가? 또한, 토스터와 전화기가 우리에게 대항할 때를 대비해 풀리지 않는 논리 문제를 비축해야 하는가? AI란 정확히 무엇을 말하는가? 이론적 등급으로 보면 ‘AI’의 종류는 영리한 엑셀 스프레드시트에서 딥소트(Deep Thought·IBM이 개발한 체스를 두는 AI)에 이르기까지 매우 다양하다. 하지만 현재 AI는 투자자 들의 관심을 배가시키기 위해 추가할 수 있는 놀라운 마법의 유행어로 느껴진다.현재 이 분야의 ‘앙팡테리블(특정 분야에서 경이로운 수준의 두각을 나타내는 신인)’인 GPT/언어 학습 모델은 스카이넷이 아니다. 이 모델은 데이터 세트(컴퓨터가 처리하거나 분석할 수 있는 형태로 존재하는 관련 정보의 집합)를 가져와 특정 스타일로 명시된 주제에 대한 이미지 또는 제한된 텍스트 조각을 포함해 해당 데이터 세트를 모방하는 출력을 생성하는 데 매우 능숙하다.  이러한 시스템은 기계 작업에 탁월한 성능을 발휘하며, 앞으로도 이 능력은 계속 개선될 것이다. 하지만 그 과정에는 ‘인식’ 은 전혀 없다. 알고리즘의 중심에는 아무것도 없으며, 그 어떤 것도 AI가 무엇을 하는지 이해하지 못한다. 이는 프로그램이 이해가 중요한 목적으로 사용될 때는 문제를 야기한다.그러한 프로그램에 질문을 한다는 것은 AI가 그 대답이 참인지 심지어 인식할 수 있는지에 대한 고려를 하지 않은 상태로 답을 구성한다는 것을 의미한다. 그 답의 입증에 대한 도전을 받을 경우, 프로그램은 이러한 질문에 대한 답변이 어떤 모습이어야 하는지에 대한 데이터 세트를 기반으로 하는 점점 더 많은 이야기를 지어낼 것이다. 이는 무엇이 ‘진실’인지에 대한 아이디어와는 완전히 다르다.\n\n\n\nⓒ 뉴스1 (출처 = NYT 터닝 포인트 2024) 여기서 초래되는 가장 큰 부작용은 학자들이 전혀 존재하지 않는 논문을 바탕으로 출처를 인용하게 된다는 점이다. 왜냐하면 알고리즘은 반드시 질문에 정확하게 답변하도록 설계되지 않았고, 형식상 적절해 보이는 결과만 생성하도록 설계됐기 때문이다. 이러한 프로그램이 사용하는 데이터 세트는 유사한 질문에 대한 많은 사람의 답변으로 구성되어 있기 때문에, 응답은 전적으로 사실일 수 있고 정확할 수 있지만, 이러한 일은 프로그램에서 흔하게 일어나는 일이다. 언어 모델은 그것이 옳은지 알 수도 없고, 신경 쓸 수도 없다. 근본적인 문제는 알고리즘이 아닌 AI라고 불리는 방식에 있다. 단순히 텍스트나 이미지 기반의 규칙이 아닌, 세상과의 대화에 존재하는 맥락적 인식 없이는 지능도 있을 수 없다. 이 ‘지능’이 프로세스 어딘가에 존재한다고 가정하면 이러한 시스템이 법적 문서를 생성하거나 식용 버섯에 대한 가이드를 작성하는 등 매우 부적절한 작업에 적용된다. 시스템은 무엇이 합법적인지, 무엇이 먹을 수 있는지는 알 수 없다. 이 시스템에는 문서에 어떤 유사성이 있는지 판단하는 패턴만이 있을 뿐이다. 이것이 현재 AI의 위협이다. 대화형 챗봇 이 지구상에서 인류를 제거한다는 위협이 아니라, 이러한 도구가 인간의 오류를 확대하는 완벽한 방법이 된다는 것이다. 우리는 부정확한 지시를 내리거나 잘못된 목적으로 AI를 사용할 수 있다. 챗GPT 스타일 시스템은 의료 진단 도구, 심리 치료사, 저널리즘 또는 학술 연구의 대체물이 아니다. 이러한 모든 역할에는 다른 핵심적인 맥락적 이해가 필요하다. 그러나 챗GPT와 같은 AI 모델은 인간에 비해 매우 경제적으로 막대한 생산량을 만들 수 있기 때문에 제안됐다. 이 AI 모델들은 부적절한 많은 시나리오에 답변하기 위해 사용될 가능성이 높다.이 시스템에서 발생하는 또 다른 철학적인 문제는 압력을 받아 상호작용하는 방식이다. 이 시스템들이 실제로 압력을 받을 수 있다는 것은 아니지만, 마치 인간처럼 공격적으로 반응한 사례가 있다. 이는 명백하게 매우 놀라운 사례다.  인간과 AI 간 대화를 보고 놀란 이유는 프로그램이 채택한 대화 방식 때문이었다. 질문자를 공격해 질문을 회피하는 것, 좌파를 비난하는 것 등은 지능이 떨어지는 챗봇의 징후가 아니다. 그들이 지적할 수 있는 것은 그 데이터 세트를 평가하고 책임을 회피하기 위한 인간의 성공적인 책략을 식별하는 인간 모방 시스템이다. 온라인 인종 차별주의자들이 만든 챗봇과 마찬가지로 비정상적인 인위적 행동으로 보이는 것은 프로그램이 우리가 설정한 나쁜 예를 너무 잘 따르기 때문일 수도 있다. 우리는 컴퓨터가 예의 바르고 공손하며 합리적이기를 기대한다. 그러나 우리가 더 높은 수준의 상호작용을 유지하지 않는 한 이러한 자질이 인간처럼 행동할 것이라는 기대감과 양립할 수는 없다. 완전한 스카이넷 스타일 AI의 위협은 어디에 있는가? 다양한 분야의 전문가들과 얘기를 나눴는데, AI를 주제로 하는 SF 작가들이 상상하는 그런 일은 결코 일어날 수 없다. 챗GPT는 확실히 그렇지 않다. 현재 그러한 생성 프로그램에 대한 심층적인 접근은 다음 AI의 돌파구를 만들 더 큰 가능성이 있는 다른 분야의 자원을 전용할 수도 있다.하지만 만약 그러한 실체가 발생한다면, 그것이 의도적이든 혹은 복잡한 시스템에서 유기적으로 생성된 것이든, 그것이 위협이 될까? AI가 원하는 것은 무엇일까? 우리가 AI에 원하는 것을 제외하고 AI가 독자적으로 원하는 것이 있을까? 악의적인 SF에 등장하는 AI의 기본 동인들은 모두 인간의 원동력이다. AI를 일상적인 인간의 경험과 단절된 엄청나게 강력한 비인격적인 괴물로 묘사하는 것은 억만장자를 묘사하는 것과 같다. 스카이넷은 우리가 그것의 스위치를 끄려고 했을 때 인류와의 전쟁을 시작했지만, AI가 이를 신경 쓸 이유는 없다. 생존본능은 수백만 년의 유기적 진화의 결과이다. 그러한 강한 AI는 인간으로서 우리가 해결할 수 없거나 원치 않는 큰문제들에 대한 해결책을 찾을 수 있기 때문에 우리의 구원이 될 수 있다. 반면에 우리가 만약 AI는 우리 인간을 모델로 삼고 있는 것이라고 고집한다면, 아마도 AI는 세상을 파괴하기 위해 자원을 게걸스럽게 먹어 치우는 괴물로 드러날 것이다. # 이 기사의 제목은 1958년에 출간된 ‘50피트 여인의 습격 (Attack of the 50-Foot Woman)’이라는 미국의 유명한 공상과학소설(SF)의 제목을 오마주한 것이다.\n\n\n\n이 기사의 저자 에이드리언 차이코프스키. ⓒ 뉴스1 (출처 = NYT 터닝 포인트 2024)\n\n",
  "thumbnail": "https://mimgnews.pstatic.net/image/origin/421/2024/01/20/7302866.jpg?type=nf106_72",
  "article_date": "2024-01-20 12:01:01",
  "site_info": "naver",
  "like_count": null,
  "viewed_count": null,
  "tags": []
}